{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "from skimage.io import imread, imshow\n",
    "import piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using os sets the \\ for me -> windows\n",
    "# using os / -> linux\n",
    "basepath = os.path.join('..', 'train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../train/\n"
     ]
    }
   ],
   "source": [
    "print(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cervix_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(glob(basepath + \"*\")):\n",
    "    # escape \\\n",
    "    cervix_type = path.split(\"/\")[-1]\n",
    "    cervix_images = sorted((glob(basepath + cervix_type + \"/*\")))\n",
    "    all_cervix_images = all_cervix_images + cervix_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../train/Type_1/0.jpg',\n",
       " '../train/Type_1/10.jpg',\n",
       " '../train/Type_1/1013.jpg',\n",
       " '../train/Type_1/1014.jpg',\n",
       " '../train/Type_1/1019.jpg']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cervix_images = pd.DataFrame({'imagepath': all_cervix_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../train/Type_1/0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../train/Type_1/10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../train/Type_1/1013.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../train/Type_1/1014.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../train/Type_1/1019.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  imagepath\n",
       "0     ../train/Type_1/0.jpg\n",
       "1    ../train/Type_1/10.jpg\n",
       "2  ../train/Type_1/1013.jpg\n",
       "3  ../train/Type_1/1014.jpg\n",
       "4  ../train/Type_1/1019.jpg"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cervix_images['filetype'] = all_cervix_images.apply(lambda row: row.imagepath.split(\".\")[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagepath</th>\n",
       "      <th>filetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../train/Type_1/0.jpg</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../train/Type_1/10.jpg</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../train/Type_1/1013.jpg</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../train/Type_1/1014.jpg</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../train/Type_1/1019.jpg</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  imagepath filetype\n",
       "0     ../train/Type_1/0.jpg      jpg\n",
       "1    ../train/Type_1/10.jpg      jpg\n",
       "2  ../train/Type_1/1013.jpg      jpg\n",
       "3  ../train/Type_1/1014.jpg      jpg\n",
       "4  ../train/Type_1/1019.jpg      jpg"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cervix_images['type'] = all_cervix_images.apply(lambda row: row.imagepath.split(\"/\")[-2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagepath</th>\n",
       "      <th>filetype</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../train/Type_1/0.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../train/Type_1/10.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../train/Type_1/1013.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../train/Type_1/1014.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../train/Type_1/1019.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  imagepath filetype    type\n",
       "0     ../train/Type_1/0.jpg      jpg  Type_1\n",
       "1    ../train/Type_1/10.jpg      jpg  Type_1\n",
       "2  ../train/Type_1/1013.jpg      jpg  Type_1\n",
       "3  ../train/Type_1/1014.jpg      jpg  Type_1\n",
       "4  ../train/Type_1/1019.jpg      jpg  Type_1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 1480 images in the whole dataset\n"
     ]
    }
   ],
   "source": [
    "print('We have a total of {} images in the whole dataset'.format(all_cervix_images.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6746016940>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAHwCAYAAADuC3p1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAICCBDkAABQkyAEAoKD/B2h1gbwRiyUqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6746016240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.set_title('Cervix Types in Dataset')\n",
    "sns.countplot(y='type',data=all_cervix_images, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percantage of each type in the data:\n",
      "Type_1: 16.8 %\n",
      "Type_2: 52.8 %\n",
      "Type_3: 30.4 %\n"
     ]
    }
   ],
   "source": [
    "print('Percantage of each type in the data:')\n",
    "for c_type in ['Type_1', 'Type_2', 'Type_3']:\n",
    "    print(c_type + ': ' + '{:.1f} %'.format(\n",
    "        len(all_cervix_images[all_cervix_images.type == c_type]) / len(all_cervix_images) * 100)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# i = 1\n",
    "# for t in all_cervix_images['type'].unique():\n",
    "#     ax = fig.add_subplot(1,3,i)\n",
    "#     i+=1\n",
    "#     f = all_cervix_images[all_cervix_images['type'] == t]['imagepath'].values[0]\n",
    "#     plt.imshow(plt.imread(f))\n",
    "#     plt.title('sample for cervix {}'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(all_cervix_images['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Type_1', 'Type_2', 'Type_3'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cervix_images['l_type'] = le.transform(all_cervix_images['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagepath</th>\n",
       "      <th>filetype</th>\n",
       "      <th>type</th>\n",
       "      <th>l_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../train/Type_1/0.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../train/Type_1/10.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../train/Type_1/1013.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../train/Type_1/1014.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../train/Type_1/1019.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  imagepath filetype    type  l_type\n",
       "0     ../train/Type_1/0.jpg      jpg  Type_1       0\n",
       "1    ../train/Type_1/10.jpg      jpg  Type_1       0\n",
       "2  ../train/Type_1/1013.jpg      jpg  Type_1       0\n",
       "3  ../train/Type_1/1014.jpg      jpg  Type_1       0\n",
       "4  ../train/Type_1/1019.jpg      jpg  Type_1       0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    781\n",
       "2    450\n",
       "0    249\n",
       "Name: l_type, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cervix_images['l_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "CPU times: user 5min 5s, sys: 38.5 s, total: 5min 43s\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(all_cervix_images)):\n",
    "    dimensions.append(imread(all_cervix_images['imagepath'].iloc[i]).shape)\n",
    "    if i % 100 == 0:\n",
    "        print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(640, 480, 3): 6,\n",
       "         (2448, 3264, 3): 29,\n",
       "         (3088, 4128, 3): 1,\n",
       "         (3096, 4128, 3): 14,\n",
       "         (3264, 2448, 3): 702,\n",
       "         (4128, 2322, 3): 17,\n",
       "         (4128, 3096, 3): 677,\n",
       "         (4160, 3120, 3): 34})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. 0\n",
      ".. 100\n",
      ".. 200\n",
      ".. 300\n",
      ".. 400\n",
      ".. 500\n",
      ".. 600\n",
      ".. 700\n",
      ".. 800\n",
      ".. 900\n",
      ".. 1000\n",
      ".. 1100\n",
      ".. 1200\n",
      ".. 1300\n",
      ".. 1400\n",
      "CPU times: user 6min 27s, sys: 20.5 s, total: 6min 47s\n",
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images = []\n",
    "for i in range(len(all_cervix_images)):\n",
    "    image = ndimage.imread(all_cervix_images['imagepath'].iloc[i], mode='RGB')\n",
    "    image_resized = misc.imresize(image, (64, 64))\n",
    "    images.append(image_resized)\n",
    "    if i % 100 == 0:\n",
    "        print('..', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, all_cervix_images['l_type'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=3)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370, 3), (1110, 3))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370, 64, 64, 3), (1110, 64, 64, 3))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True, \n",
    "                             featurewise_std_normalization=True)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=10):\n",
    "#    for i in range(0, 9):\n",
    "#        plt.subplot(330 + 1 + i)\n",
    "#        plt.imshow(X_batch[i])\n",
    "        \n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    # convolutional layer, 32 feature maps, size of 3x3 ,rectifier activation, input layer\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', input_shape=(64, 64, 3),\n",
    "    activation='relu', data_format='channels_last'))\n",
    "\n",
    "    # pool size of 2x2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # converts 2d matrix data to a vector\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # fully connected layer with 128 neurons, rectifier is used\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "\n",
    "    # output layer has 3 neurons for the 3 classes, softmax returns probability-like prediction\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1110 samples, validate on 370 samples\n",
      "Epoch 1/100\n",
      "3s - loss: 1.0263 - acc: 0.5252 - val_loss: 0.9977 - val_acc: 0.5081\n",
      "Epoch 2/100\n",
      "3s - loss: 0.9974 - acc: 0.5279 - val_loss: 0.9501 - val_acc: 0.5378\n",
      "Epoch 3/100\n",
      "3s - loss: 0.9548 - acc: 0.5378 - val_loss: 1.0145 - val_acc: 0.5054\n",
      "Epoch 4/100\n",
      "3s - loss: 0.9553 - acc: 0.5324 - val_loss: 1.0071 - val_acc: 0.5135\n",
      "Epoch 5/100\n",
      "3s - loss: 0.9039 - acc: 0.5667 - val_loss: 0.9604 - val_acc: 0.5270\n",
      "Epoch 6/100\n",
      "3s - loss: 0.8343 - acc: 0.6126 - val_loss: 1.0590 - val_acc: 0.5135\n",
      "Epoch 7/100\n",
      "3s - loss: 0.7749 - acc: 0.6640 - val_loss: 1.0853 - val_acc: 0.4973\n",
      "Epoch 8/100\n",
      "3s - loss: 0.6612 - acc: 0.7153 - val_loss: 1.1445 - val_acc: 0.4892\n",
      "Epoch 9/100\n",
      "3s - loss: 0.5114 - acc: 0.7901 - val_loss: 1.4038 - val_acc: 0.4757\n",
      "Epoch 10/100\n",
      "3s - loss: 0.3708 - acc: 0.8649 - val_loss: 1.5322 - val_acc: 0.4676\n",
      "Epoch 11/100\n",
      "3s - loss: 0.2499 - acc: 0.8991 - val_loss: 1.8992 - val_acc: 0.4730\n",
      "Epoch 12/100\n",
      "3s - loss: 0.2007 - acc: 0.9342 - val_loss: 2.6797 - val_acc: 0.3919\n",
      "Epoch 13/100\n",
      "3s - loss: 0.1346 - acc: 0.9595 - val_loss: 2.5405 - val_acc: 0.4676\n",
      "Epoch 14/100\n",
      "3s - loss: 0.0796 - acc: 0.9766 - val_loss: 3.4353 - val_acc: 0.4703\n",
      "Epoch 15/100\n",
      "3s - loss: 0.0882 - acc: 0.9694 - val_loss: 2.3886 - val_acc: 0.4703\n",
      "Epoch 16/100\n",
      "3s - loss: 0.0443 - acc: 0.9865 - val_loss: 3.2798 - val_acc: 0.4811\n",
      "Epoch 17/100\n",
      "3s - loss: 0.0367 - acc: 0.9892 - val_loss: 3.1956 - val_acc: 0.4676\n",
      "Epoch 18/100\n",
      "3s - loss: 0.0138 - acc: 0.9964 - val_loss: 3.7052 - val_acc: 0.4838\n",
      "Epoch 19/100\n",
      "3s - loss: 0.0564 - acc: 0.9820 - val_loss: 3.5356 - val_acc: 0.4568\n",
      "Epoch 20/100\n",
      "3s - loss: 0.1150 - acc: 0.9739 - val_loss: 3.4812 - val_acc: 0.4757\n",
      "Epoch 21/100\n",
      "3s - loss: 0.1095 - acc: 0.9667 - val_loss: 3.6866 - val_acc: 0.4189\n",
      "Epoch 22/100\n",
      "3s - loss: 0.0216 - acc: 0.9946 - val_loss: 3.5678 - val_acc: 0.4541\n",
      "Epoch 23/100\n",
      "3s - loss: 0.0048 - acc: 0.9991 - val_loss: 3.9505 - val_acc: 0.4486\n",
      "Epoch 24/100\n",
      "3s - loss: 0.0132 - acc: 0.9955 - val_loss: 3.8411 - val_acc: 0.4730\n",
      "Epoch 25/100\n",
      "3s - loss: 0.0039 - acc: 0.9991 - val_loss: 3.9960 - val_acc: 0.4432\n",
      "Epoch 26/100\n",
      "3s - loss: 0.0010 - acc: 1.0000 - val_loss: 4.2379 - val_acc: 0.4757\n",
      "Epoch 27/100\n",
      "3s - loss: 4.1591e-04 - acc: 1.0000 - val_loss: 4.3520 - val_acc: 0.4649\n",
      "Epoch 28/100\n",
      "3s - loss: 3.0320e-04 - acc: 1.0000 - val_loss: 4.4160 - val_acc: 0.4568\n",
      "Epoch 29/100\n",
      "3s - loss: 9.9671e-04 - acc: 1.0000 - val_loss: 4.2602 - val_acc: 0.4784\n",
      "Epoch 30/100\n",
      "3s - loss: 0.0749 - acc: 0.9757 - val_loss: 3.7542 - val_acc: 0.4514\n",
      "Epoch 31/100\n",
      "3s - loss: 0.0304 - acc: 0.9928 - val_loss: 3.5872 - val_acc: 0.4892\n",
      "Epoch 32/100\n",
      "3s - loss: 0.0043 - acc: 1.0000 - val_loss: 3.7819 - val_acc: 0.4703\n",
      "Epoch 33/100\n",
      "3s - loss: 0.0073 - acc: 0.9991 - val_loss: 4.0645 - val_acc: 0.4730\n",
      "Epoch 34/100\n",
      "3s - loss: 0.0013 - acc: 1.0000 - val_loss: 4.1566 - val_acc: 0.4649\n",
      "Epoch 35/100\n",
      "3s - loss: 6.6094e-04 - acc: 1.0000 - val_loss: 4.3280 - val_acc: 0.4703\n",
      "Epoch 36/100\n",
      "3s - loss: 4.2067e-04 - acc: 1.0000 - val_loss: 4.4410 - val_acc: 0.4730\n",
      "Epoch 37/100\n",
      "3s - loss: 2.1983e-04 - acc: 1.0000 - val_loss: 4.3598 - val_acc: 0.4649\n",
      "Epoch 38/100\n",
      "3s - loss: 6.3288e-04 - acc: 1.0000 - val_loss: 4.2156 - val_acc: 0.4838\n",
      "Epoch 39/100\n",
      "3s - loss: 2.4265e-04 - acc: 1.0000 - val_loss: 4.3196 - val_acc: 0.4784\n",
      "Epoch 40/100\n",
      "3s - loss: 1.2943e-04 - acc: 1.0000 - val_loss: 4.3689 - val_acc: 0.4784\n",
      "Epoch 41/100\n",
      "3s - loss: 1.6984e-04 - acc: 1.0000 - val_loss: 4.4516 - val_acc: 0.4757\n",
      "Epoch 42/100\n",
      "3s - loss: 7.0303e-05 - acc: 1.0000 - val_loss: 4.4939 - val_acc: 0.4676\n",
      "Epoch 43/100\n",
      "3s - loss: 6.8082e-05 - acc: 1.0000 - val_loss: 4.5350 - val_acc: 0.4676\n",
      "Epoch 44/100\n",
      "3s - loss: 1.0276e-04 - acc: 1.0000 - val_loss: 4.5390 - val_acc: 0.4730\n",
      "Epoch 45/100\n",
      "3s - loss: 6.2367e-05 - acc: 1.0000 - val_loss: 4.5955 - val_acc: 0.4784\n",
      "Epoch 46/100\n",
      "3s - loss: 2.0837e-04 - acc: 1.0000 - val_loss: 4.6638 - val_acc: 0.4919\n",
      "Epoch 47/100\n",
      "3s - loss: 6.5829e-05 - acc: 1.0000 - val_loss: 4.6933 - val_acc: 0.4838\n",
      "Epoch 48/100\n",
      "3s - loss: 3.2716e-05 - acc: 1.0000 - val_loss: 4.6933 - val_acc: 0.4784\n",
      "Epoch 49/100\n",
      "3s - loss: 5.4600e-05 - acc: 1.0000 - val_loss: 4.6852 - val_acc: 0.4784\n",
      "Epoch 50/100\n",
      "3s - loss: 1.3134e-04 - acc: 1.0000 - val_loss: 4.8379 - val_acc: 0.4946\n",
      "Epoch 51/100\n",
      "3s - loss: 1.1260e-04 - acc: 1.0000 - val_loss: 4.7037 - val_acc: 0.4946\n",
      "Epoch 52/100\n",
      "3s - loss: 4.2579e-05 - acc: 1.0000 - val_loss: 4.7586 - val_acc: 0.4811\n",
      "Epoch 53/100\n",
      "3s - loss: 2.9236e-05 - acc: 1.0000 - val_loss: 4.7696 - val_acc: 0.4811\n",
      "Epoch 54/100\n",
      "3s - loss: 2.5906e-05 - acc: 1.0000 - val_loss: 4.7987 - val_acc: 0.4892\n",
      "Epoch 55/100\n",
      "3s - loss: 1.2031e-05 - acc: 1.0000 - val_loss: 4.8106 - val_acc: 0.4838\n",
      "Epoch 56/100\n",
      "3s - loss: 1.9481e-05 - acc: 1.0000 - val_loss: 4.8436 - val_acc: 0.4838\n",
      "Epoch 57/100\n",
      "3s - loss: 2.4153e-05 - acc: 1.0000 - val_loss: 4.8148 - val_acc: 0.4784\n",
      "Epoch 58/100\n",
      "3s - loss: 4.8304e-05 - acc: 1.0000 - val_loss: 4.9422 - val_acc: 0.4892\n",
      "Epoch 59/100\n",
      "3s - loss: 2.5315e-05 - acc: 1.0000 - val_loss: 4.8487 - val_acc: 0.4838\n",
      "Epoch 60/100\n",
      "3s - loss: 2.3691e-05 - acc: 1.0000 - val_loss: 4.8219 - val_acc: 0.4865\n",
      "Epoch 61/100\n",
      "3s - loss: 1.6206e-05 - acc: 1.0000 - val_loss: 4.8505 - val_acc: 0.4811\n",
      "Epoch 62/100\n",
      "3s - loss: 1.5259e-05 - acc: 1.0000 - val_loss: 4.9290 - val_acc: 0.4865\n",
      "Epoch 63/100\n",
      "3s - loss: 9.2649e-06 - acc: 1.0000 - val_loss: 4.9409 - val_acc: 0.4865\n",
      "Epoch 64/100\n",
      "3s - loss: 9.8593e-06 - acc: 1.0000 - val_loss: 4.9518 - val_acc: 0.4865\n",
      "Epoch 65/100\n",
      "3s - loss: 4.2009e-05 - acc: 1.0000 - val_loss: 4.8936 - val_acc: 0.4676\n",
      "Epoch 66/100\n",
      "3s - loss: 1.0073e-05 - acc: 1.0000 - val_loss: 4.8964 - val_acc: 0.4703\n",
      "Epoch 67/100\n",
      "3s - loss: 1.0039e-05 - acc: 1.0000 - val_loss: 4.9031 - val_acc: 0.4838\n",
      "Epoch 68/100\n"
     ]
    }
   ],
   "source": [
    "model = conv_model()\n",
    "\n",
    "# Fit the model\n",
    "# make sure batch size is perfectly divisible\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=10,\n",
    "verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2s - loss: 6.8308 - acc: 0.5703 - val_loss: 7.9501 - val_acc: 0.5054\n",
      "Epoch 2/100\n",
      "2s - loss: 7.4687 - acc: 0.5342 - val_loss: 7.9351 - val_acc: 0.5054\n",
      "Epoch 3/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 4/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 5/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 6/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 7/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 8/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 9/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 10/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 11/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 12/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 13/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 14/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 15/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 16/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 17/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 18/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 19/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 20/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 21/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 22/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 23/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 24/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 25/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 26/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 27/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 28/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 29/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 30/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 31/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 32/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 33/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 34/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 35/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 36/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 37/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 38/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 39/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 40/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 41/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 42/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 43/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 44/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 45/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 46/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 47/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 48/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 49/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 50/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 51/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 52/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 53/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 54/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 55/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 56/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 57/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 58/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 59/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 60/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 61/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 62/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 63/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 64/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 65/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 66/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 67/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 68/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 69/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 70/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 71/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 72/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 73/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 74/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 75/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 76/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 77/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 78/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 79/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 80/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 81/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 82/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 83/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 84/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 85/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 86/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 87/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 88/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 89/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 90/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 91/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 92/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 93/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 94/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 95/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 96/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 97/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 98/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 99/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n",
      "Epoch 100/100\n",
      "2s - loss: 7.4637 - acc: 0.5369 - val_loss: 7.9356 - val_acc: 0.5054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6706b4c7f0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=10),\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    steps_per_epoch=len(X_train) / 10, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
